{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "from arxiv import Client, Search, SortCriterion\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the default API client.\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arXiv Python API: Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Search for the 10 most recent articles matching the keyword \"quantum.\"\n",
    "# search = Search(\n",
    "#   query = \"cat:cs.RO\",\n",
    "#   max_results = 100,\n",
    "#   sort_by = SortCriterion.SubmittedDate\n",
    "# )\n",
    "\n",
    "# results = client.results(search)\n",
    "\n",
    "# # `results` is a generator; you can iterate over its elements one by one...\n",
    "# for r in client.results(search):\n",
    "#   print(r.title)\n",
    "# # ...or exhaust it into a list. Careful: this is slow for large results sets.\n",
    "# all_results = list(results)\n",
    "# print([r.title for r in all_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For advanced query syntax documentation, see the arXiv API User Manual:\n",
    "# # https://arxiv.org/help/api/user-manual#query_details\n",
    "# search = Search(query = \"au:del_maestro AND ti:checkerboard\")\n",
    "# first_result = next(client.results(search))\n",
    "# print(first_result)\n",
    "\n",
    "# # Search for the paper with ID \"1605.08386v1\"\n",
    "# search_by_id = Search(id_list=[\"1605.08386v1\"])\n",
    "# # Reuse client to fetch the paper, then print its title.\n",
    "# first_result = next(client.results(search))\n",
    "# print(first_result.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers in a Specified Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv_by_date_range(query, start_date, end_date, sort_by=\"citations\"):\n",
    "    # Format the date for arXiv search\n",
    "    end_date_str = end_date.strftime('%Y%m%d')\n",
    "    start_date_str = (start_date + timedelta(days=-1)).strftime('%Y%m%d')\n",
    "\n",
    "    # Create a search query with the date filter\n",
    "    # search_query = f\"{query} AND submittedDate:[{formatted_date} TO {formatted_date}]\"\n",
    "    search_query = f\"{query} AND submittedDate:[{start_date_str} TO {end_date_str}]\"\n",
    "\n",
    "    # Perform the search\n",
    "    search = Search(\n",
    "        query=search_query,\n",
    "        max_results=100,\n",
    "        sort_by=SortCriterion.SubmittedDate\n",
    "    )\n",
    "\n",
    "    # Iterate over the results\n",
    "    results = []\n",
    "    for result in client.results(search):\n",
    "        results.append(result)\n",
    "\n",
    "    # TODO sort by citations, or any other condition\n",
    "    if sort_by == \"citations\":\n",
    "        pass # TODO\n",
    "        \n",
    "    elif sort_by == \"recency\": \n",
    "        results = sorted(results, key=lambda x: x.published.date())\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[arxiv.Result(entry_id='http://arxiv.org/abs/2406.00211v1', updated=datetime.datetime(2024, 5, 31, 21, 50, 42, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 21, 50, 42, tzinfo=datetime.timezone.utc), title='Navigating Autonomous Vehicle on Unmarked Roads with Diffusion-Based Motion Prediction and Active Inference', authors=[arxiv.Result.Author('Yufei Huang'), arxiv.Result.Author('Yulin Li'), arxiv.Result.Author('Andrea Matta'), arxiv.Result.Author('Mohsen Jafari')], summary=\"This paper presents a novel approach to improving autonomous vehicle control\\nin environments lacking clear road markings by integrating a diffusion-based\\nmotion predictor within an Active Inference Framework (AIF). Using a simulated\\nparking lot environment as a parallel to unmarked roads, we develop and test\\nour model to predict and guide vehicle movements effectively. The\\ndiffusion-based motion predictor forecasts vehicle actions by leveraging\\nprobabilistic dynamics, while AIF aids in decision-making under uncertainty.\\nUnlike traditional methods such as Model Predictive Control (MPC) and\\nReinforcement Learning (RL), our approach reduces computational demands and\\nrequires less extensive training, enhancing navigation safety and efficiency.\\nOur results demonstrate the model's capability to navigate complex scenarios,\\nmarking significant progress in autonomous driving technology.\", comment=None, journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO', 'cs.SY', 'eess.SY'], links=[arxiv.Result.Link('http://arxiv.org/abs/2406.00211v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2406.00211v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2406.00119v1', updated=datetime.datetime(2024, 5, 31, 18, 21, 50, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 18, 21, 50, tzinfo=datetime.timezone.utc), title='Through the Clutter: Exploring the Impact of Complex Environments on the Legibility of Robot Motion', authors=[arxiv.Result.Author('Melanie Schmidt-Wolf'), arxiv.Result.Author('Tyler Becker'), arxiv.Result.Author('Denielle Oliva'), arxiv.Result.Author('Monica Nicolescu'), arxiv.Result.Author('David Feil-Seifer')], summary='The environments in which the collaboration of a robot would be the most\\nhelpful to a person are frequently uncontrolled and cluttered with many objects\\npresent. Legible robot arm motion is crucial in tasks like these in order to\\navoid possible collisions, improve the workflow and help ensure the safety of\\nthe person. Prior work in this area, however, focuses on solutions that are\\ntested only in uncluttered environments and there are not many results taken\\nfrom cluttered environments. In this research we present a measure for\\nclutteredness based on an entropic measure of the environment, and a novel\\nmotion planner based on potential fields. Both our measures and the planner\\nwere tested in a cluttered environment meant to represent a more typical tool\\nsorting task for which the person would collaborate with a robot. The in-person\\nvalidation study with Baxter robots shows a significant improvement in\\nlegibility of our proposed legible motion planner compared to the current\\nstate-of-the-art legible motion planner in cluttered environments. Further, the\\nresults show a significant difference in the performance of the planners in\\ncluttered and uncluttered environments, and the need to further explore legible\\nmotion in cluttered environments. We argue that the inconsistency of our\\nresults in cluttered environments with those obtained from uncluttered\\nenvironments points out several important issues with the current research\\nperformed in the area of legible motion planners.', comment=None, journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO'], links=[arxiv.Result.Link('http://arxiv.org/abs/2406.00119v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2406.00119v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2406.00114v2', updated=datetime.datetime(2024, 6, 8, 2, 41, 13, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 18, 5, 47, tzinfo=datetime.timezone.utc), title='Dynamic Multi-Objective Lion Swarm Optimization with Multi-strategy Fusion: An application in 6R robot trajectory planning', authors=[arxiv.Result.Author('Bao Liu'), arxiv.Result.Author('Tianbao Liu'), arxiv.Result.Author('Zhongshuo Hu'), arxiv.Result.Author('Fei Ye'), arxiv.Result.Author('Lei Gao')], summary='The advancement of industrialization has spurred the development of\\ninnovative swarm intelligence algorithms, with Lion Swarm Optimization (LSO)\\nnotable for its robustness, parallelism, simplicity, and efficiency. While LSO\\nexcels in single-objective optimization, its multi-objective variants face\\nchallenges such as poor initialization, local optima entrapment, and so on.\\nThis study proposes Dynamic Multi-Objective Lion Swarm Optimization with\\nMulti-strategy Fusion (MF-DMOLSO) to address these limitations. MF-DMOLSO\\ncomprises three key components: initialization, swarm position update, and\\nexternal archive update. The initialization unit employs chaotic mapping for\\nuniform population distribution. The position update unit enhances behavior\\npatterns and step size formulas for cub lions, incorporating crowding degree\\nsorting, Pareto non-dominated sorting, and Levy flight to improve convergence\\nspeed and global search capabilities. Reference points guide convergence in\\nhigher-dimensional spaces, maintaining population diversity. An adaptive\\ncold-hot start strategy generates a population responsive to environmental\\nchanges. The external archive update unit re-evaluates solutions based on\\nnon-domination and diversity to form the new population. Evaluations on\\nbenchmark functions showed MF-DMOLSO surpassed multi-objective particle swarm\\noptimization, non-dominated sorting genetic algorithm II, and multi-objective\\nlion swarm optimization, exceeding 90% accuracy for two-objective and 97% for\\nthree-objective problems. Compared to non-dominated sorting genetic algorithm\\nIII, MF-DMOLSO showed a 60% improvement. Applied to 6R robot trajectory\\nplanning, MF-DMOLSO optimized running time and maximum acceleration to 8.3s and\\n0.3pi rad/s^2, achieving a set coverage rate of 70.97% compared to 2% by\\nmulti-objective particle swarm optimization, thus improving efficiency and\\nreducing mechanical dither.', comment=None, journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO', 'cs.NE'], links=[arxiv.Result.Link('http://arxiv.org/abs/2406.00114v2', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2406.00114v2', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.21056v1', updated=datetime.datetime(2024, 5, 31, 17, 47, 22, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 17, 47, 22, tzinfo=datetime.timezone.utc), title='An Organic Weed Control Prototype using Directed Energy and Deep Learning', authors=[arxiv.Result.Author('Deng Cao'), arxiv.Result.Author('Hongbo Zhang'), arxiv.Result.Author('Rajveer Dhillon')], summary='Organic weed control is a vital to improve crop yield with a sustainable\\napproach. In this work, a directed energy weed control robot prototype\\nspecifically designed for organic farms is proposed. The robot uses a novel\\ndistributed array robot (DAR) unit for weed treatment. Soybean and corn\\ndatabases are built to train deep learning neural nets to perform weed\\nrecognition. The initial deep learning neural nets show a high performance in\\nclassifying crops. The robot uses a patented directed energy plant eradication\\nrecipe that is completely organic and UV-C free, with no chemical damage or\\nphysical disturbance to the soil. The deep learning can classify 8 common weed\\nspecies in a soybean field under natural environment with up to 98% accuracy.', comment=None, journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO', 'cs.AI', 'cs.CV'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.21056v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.21056v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.21044v1', updated=datetime.datetime(2024, 5, 31, 17, 38, 19, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 17, 38, 19, tzinfo=datetime.timezone.utc), title='Designing for Fairness in Human-Robot Interactions', authors=[arxiv.Result.Author('Houston Claure')], summary='The foundation of successful human collaboration is deeply rooted in the\\nprinciples of fairness. As robots are increasingly prevalent in various parts\\nof society where they are working alongside groups and teams of humans, their\\nability to understand and act according to principles of fairness becomes\\ncrucial for their effective integration. This is especially critical when\\nrobots are part of multi-human teams, where they must make continuous decisions\\nregarding the allocation of resources. These resources can be material, such as\\ntools, or communicative, such as gaze direction, and must be distributed fairly\\namong team members to ensure optimal team performance and healthy group\\ndynamics. Therefore, our research focuses on understanding how robots can\\neffectively participate within human groups by making fair decisions while\\ncontributing positively to group dynamics and outcomes. In this paper, I\\ndiscuss advances toward ensuring that robots are capable of considering human\\nnotions of fairness in their decision-making.', comment=None, journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO', 'cs.HC'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.21044v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.21044v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.20969v1', updated=datetime.datetime(2024, 5, 31, 16, 16, 28, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 16, 16, 28, tzinfo=datetime.timezone.utc), title='Design, Calibration, and Control of Compliant Force-sensing Gripping Pads for Humanoid Robots', authors=[arxiv.Result.Author('Yuanfeng Han'), arxiv.Result.Author('Boren Jiang'), arxiv.Result.Author('Gregory S. Chirikjian')], summary='This paper introduces a pair of low-cost, light-weight and compliant\\nforce-sensing gripping pads used for manipulating box-like objects with\\nsmaller-sized humanoid robots. These pads measure normal gripping forces and\\ncenter of pressure (CoP). A calibration method is developed to improve the CoP\\nmeasurement accuracy. A hybrid force-alignment-position control framework is\\nproposed to regulate the gripping forces and to ensure the surface alignment\\nbetween the grippers and the object. Limit surface theory is incorporated as a\\ncontact friction modeling approach to determine the magnitude of gripping\\nforces for slippage avoidance. The integrated hardware and software system is\\ndemonstrated with a NAO humanoid robot. Experiments show the effectiveness of\\nthe overall approach.', comment='21 pages, 16 figures, Published in ASME Journal of Mechanisms and\\n  Robotics', journal_ref='Journal of Mechanisms and Robotics, 15, 031010,2023', doi=None, primary_category='cs.RO', categories=['cs.RO', 'cs.SY', 'eess.SY'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.20969v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.20969v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.20896v1', updated=datetime.datetime(2024, 5, 31, 15, 5, 5, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 15, 5, 5, tzinfo=datetime.timezone.utc), title='SPARROW: Smart Precision Agriculture Robot for Ridding of Weeds', authors=[arxiv.Result.Author('Dhanushka Balasingham'), arxiv.Result.Author('Sadeesha Samarathunga'), arxiv.Result.Author('Gayantha Godakanda Arachchige'), arxiv.Result.Author('Anuththara Bandara'), arxiv.Result.Author('Sasini Wellalage'), arxiv.Result.Author('Dinithi Pandithage'), arxiv.Result.Author('Mahaadikara M. D. J. T Hansika'), arxiv.Result.Author('Rajitha de Silva')], summary='The advancements in precision agriculture are vital to support the increasing\\ndemand for global food supply. Precision spot spraying is a major step towards\\nreducing chemical usage for pest and weed control in agriculture. A novel spot\\nspraying algorithm that autonomously detects weeds and performs trajectory\\nplanning for the sprayer nozzle has been proposed. Furthermore, this research\\nintroduces a vision-based autonomous navigation system that operates through\\nthe detected crop row, effectively synchronizing with an autonomous spraying\\nalgorithm. This proposed system is characterized by its cost effectiveness that\\nenable the autonomous spraying of herbicides onto detected weeds.', comment='submitted to 5th INTERNATIONAL CONFERENCE OF EMERGING TECHNOLOGIES\\n  2024, BELGAUM, INDIA', journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.20896v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.20896v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.20883v1', updated=datetime.datetime(2024, 5, 31, 14, 55, 44, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 14, 55, 44, tzinfo=datetime.timezone.utc), title='Scalable Distance-based Multi-Agent Relative State Estimation via Block Multiconvex Optimization', authors=[arxiv.Result.Author('Tianyue Wu'), arxiv.Result.Author('Gongye Zaitian'), arxiv.Result.Author('Qianhao Wang'), arxiv.Result.Author('Fei Gao')], summary='This paper explores the distance-based relative state estimation problem in\\nlarge-scale systems, which is hard to solve effectively due to its\\nhigh-dimensionality and non-convexity. In this paper, we alleviate this\\ninherent hardness to simultaneously achieve scalability and robustness of\\ninference on this problem. Our idea is launched from a universal geometric\\nformulation, called \\\\emph{generalized graph realization}, for the\\ndistance-based relative state estimation problem. Based on this formulation, we\\nintroduce two collaborative optimization models, one of which is convex and\\nthus globally solvable, and the other enables fast searching on non-convex\\nlandscapes to refine the solution offered by the convex one. Importantly, both\\nmodels enjoy \\\\emph{multiconvex} and \\\\emph{decomposable} structures, allowing\\nefficient and safe solutions using \\\\emph{block coordinate descent} that enjoys\\nscalability and a distributed nature. The proposed algorithms collaborate to\\ndemonstrate superior or comparable solution precision to the current\\ncentralized convex relaxation-based methods, which are known for their high\\noptimality. Distinctly, the proposed methods demonstrate scalability beyond the\\nreach of previous convex relaxation-based methods. We also demonstrate that the\\ncombination of the two proposed algorithms achieves a more robust pipeline than\\ndeploying the local search method alone in a continuous-time scenario.', comment='To appear in Robotics: Science and System 2024', journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.20883v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.20883v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.20858v1', updated=datetime.datetime(2024, 5, 31, 14, 42, 36, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 14, 42, 36, tzinfo=datetime.timezone.utc), title='CSDO: Enhancing Efficiency and Success in Large-Scale Multi-Vehicle Trajectory Planning', authors=[arxiv.Result.Author('Yibin Yang'), arxiv.Result.Author('Shaobing Xu'), arxiv.Result.Author('Xintao Yan'), arxiv.Result.Author('Junkai Jiang'), arxiv.Result.Author('Jianqiang Wang'), arxiv.Result.Author('Heye Huang')], summary='This paper presents an efficient algorithm, naming Centralized Searching and\\nDecentralized Optimization (CSDO), to find feasible solution for large-scale\\nMulti-Vehicle Trajectory Planning (MVTP) problem. Due to the intractable growth\\nof non-convex constraints with the number of agents, exploring various homotopy\\nclasses that imply different convex domains, is crucial for finding a feasible\\nsolution. However, existing methods struggle to explore various homotopy\\nclasses efficiently due to combining it with time-consuming precise trajectory\\nsolution finding. CSDO, addresses this limitation by separating them into\\ndifferent levels and integrating an efficient Multi-Agent Path Finding (MAPF)\\nalgorithm to search homotopy classes. It first searches for a coarse initial\\nguess using a large search step, identifying a specific homotopy class.\\nSubsequent decentralized Quadratic Programming (QP) refinement processes this\\nguess, resolving minor collisions efficiently. Experimental results demonstrate\\nthat CSDO outperforms existing MVTP algorithms in large-scale, high-density\\nscenarios, achieving up to 95% success rate in 50m $\\\\times$ 50m random\\nscenarios around one second. Source codes are released in\\nhttps://github.com/YangSVM/CSDOTrajectoryPlanning.', comment='8 pages, 7 figures. This work has been submitted to the IEEE for\\n  possible publication. Copyright may be transferred without notice, after\\n  which this version may no longer be accessible', journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.20858v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.20858v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.20820v1', updated=datetime.datetime(2024, 5, 31, 14, 15, 10, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 14, 15, 10, tzinfo=datetime.timezone.utc), title='Constrained Dynamics Simulation: More With Less', authors=[arxiv.Result.Author('Ajay Suresha Sathya')], summary='Efficient robot dynamics simulation is a fundamental problem key for robot\\ncontrol, identification, design and analysis. This research statement explores\\nmy current progress in this field and future research directions.', comment='Accepted submission to RSS:24 Pioneers Workshop', journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.20820v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.20820v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.20743v1', updated=datetime.datetime(2024, 5, 31, 10, 13, 17, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 10, 13, 17, tzinfo=datetime.timezone.utc), title='Trajectory Forecasting through Low-Rank Adaptation of Discrete Latent Codes', authors=[arxiv.Result.Author('Riccardo Benaglia'), arxiv.Result.Author('Angelo Porrello'), arxiv.Result.Author('Pietro Buzzega'), arxiv.Result.Author('Simone Calderara'), arxiv.Result.Author('Rita Cucchiara')], summary='Trajectory forecasting is crucial for video surveillance analytics, as it\\nenables the anticipation of future movements for a set of agents, e.g.\\nbasketball players engaged in intricate interactions with long-term intentions.\\nDeep generative models offer a natural learning approach for trajectory\\nforecasting, yet they encounter difficulties in achieving an optimal balance\\nbetween sampling fidelity and diversity. We address this challenge by\\nleveraging Vector Quantized Variational Autoencoders (VQ-VAEs), which utilize a\\ndiscrete latent space to tackle the issue of posterior collapse. Specifically,\\nwe introduce an instance-based codebook that allows tailored latent\\nrepresentations for each example. In a nutshell, the rows of the codebook are\\ndynamically adjusted to reflect contextual information (i.e., past motion\\npatterns extracted from the observed trajectories). In this way, the\\ndiscretization process gains flexibility, leading to improved reconstructions.\\nNotably, instance-level dynamics are injected into the codebook through\\nlow-rank updates, which restrict the customization of the codebook to a lower\\ndimension space. The resulting discrete space serves as the basis of the\\nsubsequent step, which regards the training of a diffusion-based predictive\\nmodel. We show that such a two-fold framework, augmented with instance-level\\ndiscretization, leads to accurate and diverse forecasts, yielding\\nstate-of-the-art performance on three established benchmarks.', comment='15 pages, 3 figures, 5 tables', journal_ref=None, doi=None, primary_category='cs.CV', categories=['cs.CV', 'cs.AI', 'cs.LG', 'cs.RO'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.20743v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.20743v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.20593v1', updated=datetime.datetime(2024, 5, 31, 3, 8, 19, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 3, 8, 19, tzinfo=datetime.timezone.utc), title='Excitable crawling', authors=[arxiv.Result.Author('Juncal Arbelaiz'), arxiv.Result.Author('Alessio Franci'), arxiv.Result.Author('Naomi Ehrich Leonard'), arxiv.Result.Author('Rodolphe Sepulchre'), arxiv.Result.Author('Bassam Bamieh')], summary=\"We propose and analyze the suitability of a spiking controller to engineer\\nthe locomotion of a soft robotic crawler. Inspired by the FitzHugh-Nagumo model\\nof neural excitability, we design a bistable controller with an electrical\\nflipflop circuit representation capable of generating spikes on-demand when\\ncoupled to the passive crawler mechanics. A proprioceptive sensory signal from\\nthe crawler mechanics turns bistability of the controller into a rhythmic\\nspiking. The output voltage, in turn, activates the crawler's actuators to\\ngenerate movement through peristaltic waves. We show through geometric analysis\\nthat this control strategy achieves endogenous crawling. The electro-mechanical\\nsensorimotor interconnection provides embodied negative feedback regulation,\\nfacilitating locomotion. Dimensional analysis provides insights on the\\ncharacteristic scales in the crawler's mechanical and electrical dynamics, and\\nhow they determine the crawling gait. Adaptive control of the electrical scales\\nto optimally match the mechanical scales can be envisioned to achieve further\\nefficiency, as in homeostatic regulation of neuronal circuits. Our approach can\\nscale up to multiple sensorimotor loops inspired by biological central pattern\\ngenerators.\", comment='5 pages, MTNS 2024 extended abstract', journal_ref=None, doi=None, primary_category='eess.SY', categories=['eess.SY', 'cs.RO', 'cs.SY'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.20593v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.20593v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.20579v1', updated=datetime.datetime(2024, 5, 31, 2, 17, 51, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 2, 17, 51, tzinfo=datetime.timezone.utc), title='HOPE: A Reinforcement Learning-based Hybrid Policy Path Planner for Diverse Parking Scenarios', authors=[arxiv.Result.Author('Mingyang Jiang'), arxiv.Result.Author('Yueyuan Li'), arxiv.Result.Author('Songan Zhang'), arxiv.Result.Author('Chunxiang Wang'), arxiv.Result.Author('Ming Yang')], summary=\"Path planning plays a pivotal role in automated parking, yet current methods\\nstruggle to efficiently handle the intricate and diverse parking scenarios. One\\npotential solution is the reinforcement learning-based method, leveraging its\\nexploration in unrecorded situations. However, a key challenge lies in training\\nreinforcement learning methods is the inherent randomness in converging to a\\nfeasible policy. This paper introduces a novel solution, the Hybrid POlicy Path\\nplannEr (HOPE), which integrates a reinforcement learning agent with\\nReeds-Shepp curves, enabling effective planning across diverse scenarios. The\\npaper presents a method to calculate and implement an action mask mechanism in\\npath planning, significantly boosting the efficiency and effectiveness of\\nreinforcement learning training. A transformer is employed as the network\\nstructure to fuse environmental information and generate planned paths. To\\nfacilitate the training and evaluation of the proposed planner, we propose a\\ncriterion for categorizing the difficulty level of parking scenarios based on\\nspace and obstacle distribution. Experimental results demonstrate that our\\napproach outperforms typical rule-based algorithms and traditional\\nreinforcement learning methods, showcasing higher planning success rates and\\ngeneralization across various scenarios. The code for our solution will be\\nopenly available on \\\\href{GitHub}{https://github.com/jiamiya/HOPE}. % after the\\npaper's acceptance.\", comment='10 pages, 6 tables, 5 figures, 1 page appendix', journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO', 'cs.LG'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.20579v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.20579v1', title='pdf', rel='related', content_type=None)]),\n",
       " arxiv.Result(entry_id='http://arxiv.org/abs/2405.20567v1', updated=datetime.datetime(2024, 5, 31, 1, 10, 29, tzinfo=datetime.timezone.utc), published=datetime.datetime(2024, 5, 31, 1, 10, 29, tzinfo=datetime.timezone.utc), title='Fast Decentralized State Estimation for Legged Robot Locomotion via EKF and MHE', authors=[arxiv.Result.Author('Jiarong Kang'), arxiv.Result.Author('Yi Wang'), arxiv.Result.Author('Xiaobin Xiong')], summary='In this paper, we present a fast and decentralized state estimation framework\\nfor the control of legged locomotion. The nonlinear estimation of the floating\\nbase states is decentralized to an orientation estimation via Extended Kalman\\nFilter (EKF) and a linear velocity estimation via Moving Horizon Estimation\\n(MHE). The EKF fuses the inertia sensor with vision to estimate the floating\\nbase orientation. The MHE uses the estimated orientation with all the sensors\\nwithin a time window in the past to estimate the linear velocities based on a\\ntime-varying linear dynamics formulation of the interested states with state\\nconstraints. More importantly, a marginalization method based on the\\noptimization structure of the full information filter (FIF) is proposed to\\nconvert the equality-constrained FIF to an equivalent MHE. This decoupling of\\nstate estimation promotes the desired balance of computation efficiency,\\naccuracy of estimation, and the inclusion of state constraints. The proposed\\nmethod is shown to be capable of providing accurate state estimation to several\\nlegged robots, including the highly dynamic hopping robot PogoX, the bipedal\\nrobot Cassie, and the quadrupedal robot Unitree Go1, with a frequency at 200 Hz\\nand a window interval of 0.1s.', comment=None, journal_ref=None, doi=None, primary_category='cs.RO', categories=['cs.RO'], links=[arxiv.Result.Link('http://arxiv.org/abs/2405.20567v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/2405.20567v1', title='pdf', rel='related', content_type=None)])]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_arxiv_by_date_range(\"cat:cs.RO\", datetime.fromisoformat(\"2024-06-01\").date(), datetime.fromisoformat(\"2024-06-01\").date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for Semantic Scholar Article by Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_semantic_scholar(title, author=None, api_key=None):\n",
    "    url = 'https://api.semanticscholar.org/graph/v1/paper/search'\n",
    "    query = title\n",
    "    if author:\n",
    "        query += f\" {author}\"\n",
    "    \n",
    "    params = {\n",
    "        'query': query,\n",
    "        # 'fields': 'title,authors,externalIds,corpusId',\n",
    "        'fields': 'title,authors,externalIds,corpusId,citationCount',\n",
    "        'limit': 1\n",
    "    }\n",
    "    \n",
    "    # headers = {}\n",
    "    # if api_key:\n",
    "    #     headers['x-api-key'] = api_key\n",
    "    \n",
    "    # response = requests.get(url, params=params, headers=headers)\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    if 'data' in data and len(data['data']) > 0:\n",
    "        paper = data['data'][0]\n",
    "        return paper\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paperId': '7ba8b89bf4f915e89bcdccdcdea9e52f7739bfc2', 'externalIds': {'ArXiv': '2406.00518', 'CorpusId': 270214475}, 'corpusId': 270214475, 'title': 'Learning to Play Air Hockey with Model-Based Deep Reinforcement Learning', 'citationCount': 1, 'authors': [{'authorId': '2179879892', 'name': 'Andrej Orsula'}]}\n",
      "{'paperId': 'b0bef6fbb26d3b0540df8d52fc57c831c791e0ce', 'externalIds': {'ArXiv': '2406.00504', 'CorpusId': 270217757}, 'corpusId': 270217757, 'title': 'Research on an Autonomous UAV Search and Rescue System Based on the Improved', 'citationCount': 0, 'authors': [{'authorId': '2164731402', 'name': 'Haobin Chen'}, {'authorId': '2304445355', 'name': 'Junyu Tao'}, {'authorId': '2304673169', 'name': 'Bize Zhou'}, {'authorId': '2304922034', 'name': 'Xiaoyan Liu'}]}\n",
      "{'paperId': '5115c12b124424f50b8576adc4df83b7c412daf3', 'externalIds': {'ArXiv': '2406.00485', 'CorpusId': 270218671}, 'corpusId': 270218671, 'title': 'TacShade A New 3D-printed Soft Optical Tactile Sensor Based on Light, Shadow and Greyscale for Shape Reconstruction', 'citationCount': 0, 'authors': [{'authorId': '2259549003', 'name': 'Zhenyu Lu'}, {'authorId': '2304462817', 'name': 'Jialong Yang'}, {'authorId': '2296388921', 'name': 'Haoran Li'}, {'authorId': '2304514079', 'name': 'Yifan Li'}, {'authorId': '2089052546', 'name': 'Weiyong Si'}, {'authorId': '2276954856', 'name': 'Nathan Lepora'}, {'authorId': '2260627450', 'name': 'Chenguang Yang'}]}\n",
      "{'paperId': '0ef5cb867a83017d38ac454901190396e880d3b5', 'externalIds': {'DBLP': 'conf/aaai/MirakhorG0B24', 'ArXiv': '2406.00451', 'DOI': '10.1609/aaai.v38i9.28902', 'CorpusId': 268692431}, 'corpusId': 268692431, 'title': 'Task Planning for Object Rearrangement in Multi-Room Environments', 'citationCount': 0, 'authors': [{'authorId': '2293398140', 'name': 'Karan Mirakhor'}, {'authorId': '2293450310', 'name': 'Sourav Ghosh'}, {'authorId': '2070467275', 'name': 'Dipanjan Das'}, {'authorId': '3262263', 'name': 'Brojeshwar Bhowmick'}]}\n",
      "{'paperId': '003112c4c2f5e1c97bc88d92afb1a0fc29525cec', 'externalIds': {'ArXiv': '2406.00447', 'CorpusId': 270214607}, 'corpusId': 270214607, 'title': 'DroneVis: Versatile Computer Vision Library for Drones', 'citationCount': 0, 'authors': [{'authorId': '2182687736', 'name': 'Ahmed Heakl'}, {'authorId': '2104334498', 'name': 'F. Youssef'}, {'authorId': '2160379240', 'name': 'Victor Parque'}, {'authorId': '2304473404', 'name': 'Walid Gomaa'}]}\n",
      "{'paperId': 'd381f274bcf3b869e5bcff48e4ef3d471c1d0a0e', 'externalIds': {'ArXiv': '2406.00439', 'CorpusId': 270211810}, 'corpusId': 270211810, 'title': 'Learning Manipulation by Predicting Interaction', 'citationCount': 0, 'authors': [{'authorId': '2290180535', 'name': 'Jia Zeng'}, {'authorId': '2290184536', 'name': 'Qingwen Bu'}, {'authorId': '2262615613', 'name': 'Bangjun Wang'}, {'authorId': '2201319923', 'name': 'Wenke Xia'}, {'authorId': '2304516619', 'name': 'Li Chen'}, {'authorId': '2305454696', 'name': 'Hao Dong'}, {'authorId': '2304550745', 'name': 'Haoming Song'}, {'authorId': '2304591834', 'name': 'Dong Wang'}, {'authorId': '2265546488', 'name': 'Di Hu'}, {'authorId': '2262515628', 'name': 'Ping Luo'}, {'authorId': '2304974174', 'name': 'Heming Cui'}, {'authorId': '2256773314', 'name': 'Bin Zhao'}, {'authorId': '2192821449', 'name': 'Xuelong Li'}, {'authorId': '2290187706', 'name': 'Yu Qiao'}, {'authorId': '2290243003', 'name': 'Hongyang Li'}]}\n",
      "{'paperId': 'cd9348ed9f4d81ac533529f5559652f25bc01b24', 'externalIds': {'ArXiv': '2406.00430', 'CorpusId': 270215495}, 'corpusId': 270215495, 'title': 'Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM Planners', 'citationCount': 0, 'authors': [{'authorId': '2304555983', 'name': 'Zhi Zheng'}, {'authorId': '2304520165', 'name': 'Qian Feng'}, {'authorId': '2304497178', 'name': 'Hang Li'}, {'authorId': '2262217323', 'name': 'Alois Knoll'}, {'authorId': '2296219375', 'name': 'Jianxiang Feng'}]}\n",
      "{'paperId': '7b4b4c3d9cdb92d565c809f6e8ee46ec7f618041', 'externalIds': {'ArXiv': '2406.00375', 'CorpusId': 270209799}, 'corpusId': 270209799, 'title': 'Teledrive: An Embodied AI based Telepresence System', 'citationCount': 0, 'authors': [{'authorId': '2148266416', 'name': 'Snehasis Banerjee'}, {'authorId': '2305331394', 'name': 'Sayan Paul'}, {'authorId': '1832905919', 'name': 'R. Roychoudhury'}, {'authorId': '2304440143', 'name': 'Abhijan Bhattacharya'}, {'authorId': '2261388040', 'name': 'Chayan Sarkar'}, {'authorId': '2051296555', 'name': 'A. Sau'}, {'authorId': '40794855', 'name': 'Pradip Pramanick'}, {'authorId': '3262263', 'name': 'Brojeshwar Bhowmick'}]}\n",
      "{'paperId': '1baf06b24501e71b915922856dc9fdb16e72a8dd', 'externalIds': {'ArXiv': '2406.00364', 'CorpusId': 270215035}, 'corpusId': 270215035, 'title': 'Cognitive Manipulation: Semi-supervised Visual Representation and Classroom-to-real Reinforcement Learning for Assembly in Semi-structured Environments', 'citationCount': 0, 'authors': [{'authorId': '2295085904', 'name': 'Chuang Wang'}, {'authorId': '2026990081', 'name': 'Lie Yang'}, {'authorId': '2294904938', 'name': 'Ze Lin'}, {'authorId': '2237588791', 'name': 'Yizhi Liao'}, {'authorId': '2295067579', 'name': 'Gang Chen'}, {'authorId': '2268185366', 'name': 'Longhan Xie'}]}\n",
      "{'paperId': '359a071c56a3a3ef5d14c704b03bd9ac23ebc4d4', 'externalIds': {'ArXiv': '2406.00315', 'CorpusId': 270217209}, 'corpusId': 270217209, 'title': 'Precision and Adaptability of YOLOv5 and YOLOv8 in Dynamic Robotic Environments', 'citationCount': 0, 'authors': [{'authorId': '2022297535', 'name': 'V. A. Kich'}, {'authorId': '2304483748', 'name': 'Muhammad A. Muttaqien'}, {'authorId': '2281139454', 'name': 'Junya Toyama'}, {'authorId': '2304483901', 'name': 'Ryutaro Miyoshi'}, {'authorId': '2304484281', 'name': 'Yosuke Ida'}, {'authorId': '2267783130', 'name': 'Akihisa Ohya'}, {'authorId': '2281142253', 'name': 'Hisashi Date'}]}\n",
      "{'paperId': 'ba1c1c1e9497368d7bd80d549e08c1c97e2a7e55', 'externalIds': {'ArXiv': '2406.00313', 'CorpusId': 270218247}, 'corpusId': 270218247, 'title': 'From Seedling to Harvest: The GrowingSoy Dataset for Weed Detection in Soy Crops via Instance Segmentation', 'citationCount': 0, 'authors': [{'authorId': '2181500957', 'name': 'Raul Steinmetz'}, {'authorId': '2022297535', 'name': 'V. A. Kich'}, {'authorId': '2299683898', 'name': 'Henrique Krever'}, {'authorId': '2304487387', 'name': 'Joao D. Rigo Mazzarolo'}, {'authorId': '103883886', 'name': 'R. B. Grando'}, {'authorId': '2304487357', 'name': 'Vinicius Marini'}, {'authorId': '40240663', 'name': 'Celio Trois'}, {'authorId': '2257080480', 'name': 'Ard Nieuwenhuizen'}]}\n",
      "{'paperId': '8104fc7c08d410ef1c9c715f816a55648e678a1f', 'externalIds': {'ArXiv': '2406.00312', 'CorpusId': 270211658}, 'corpusId': 270211658, 'title': 'NuRF: Nudging the Particle Filter in Radiance Fields for Robot Visual Localization', 'citationCount': 0, 'authors': [{'authorId': '2304457541', 'name': 'Wugang Meng'}, {'authorId': '2304744391', 'name': 'Tianfu Wu'}, {'authorId': '2305054989', 'name': 'Huan Yin'}, {'authorId': '2300250686', 'name': 'Fumin Zhang'}]}\n"
     ]
    }
   ],
   "source": [
    "for title in titles:\n",
    "    print(search_semantic_scholar(title))\n",
    "    # paper = search_semantic_scholar(title)\n",
    "    # if paper is None: continue\n",
    "    # print(f\"{paper['title']} (cited by {paper['citationCount']})\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.semanticscholar.org/graph/v1/paper/search'\n",
    "query = \"Learning to Play Air Hockey with Model-Based Deep Reinforcement Learning\"\n",
    "\n",
    "params = {\n",
    "    'query': query,\n",
    "    'fields': 'title,authors,externalIds,corpusId',\n",
    "    'limit': 1\n",
    "}\n",
    "\n",
    "# headers = {}\n",
    "# if api_key:\n",
    "#     headers['x-api-key'] = api_key\n",
    "\n",
    "# response = requests.get(url, params=params, headers=headers)\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "if 'data' in data and len(data['data']) > 0:\n",
    "    paper = data['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 20,\n",
       " 'offset': 0,\n",
       " 'next': 1,\n",
       " 'data': [{'paperId': '7ba8b89bf4f915e89bcdccdcdea9e52f7739bfc2',\n",
       "   'externalIds': {'ArXiv': '2406.00518', 'CorpusId': 270214475},\n",
       "   'corpusId': 270214475,\n",
       "   'title': 'Learning to Play Air Hockey with Model-Based Deep Reinforcement Learning',\n",
       "   'authors': [{'authorId': '2179879892', 'name': 'Andrej Orsula'}]}]}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch-Retrieving Citation Counts w/ Semantic Scholar API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import time\n",
    "\n",
    "# def get_citation_counts(paper_ids, api_key):\n",
    "#     url = 'https://api.semanticscholar.org/graph/v1/paper/batch'\n",
    "#     headers = {'x-api-key': api_key}\n",
    "    \n",
    "#     # Prepare the request payload\n",
    "#     request_payload = {\n",
    "#         \"ids\": paper_ids,\n",
    "#         \"fields\": \"title,citationCount\"\n",
    "#     }\n",
    "\n",
    "#     response = requests.post(url, headers=headers, json=request_payload)\n",
    "#     data = response.json()\n",
    "    \n",
    "#     citation_counts = {}\n",
    "#     for paper in data['data']:\n",
    "#         title = paper.get('title', 'Unknown Title')\n",
    "#         citation_count = paper.get('citationCount', 0)\n",
    "#         citation_counts[title] = citation_count\n",
    "    \n",
    "#     return citation_counts\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     api_key = 'YOUR_API_KEY'  # Replace with your Semantic Scholar API key\n",
    "#     paper_ids = [\n",
    "#         # \"10.1109/5.771073\",  # Replace with actual DOIs or paper IDs\n",
    "#         # \"10.1038/nature24271\",\n",
    "#         \"2406.00518\",\n",
    "#         \"2406.00504\",\n",
    "#         \"2406.00485\",\n",
    "#         \"2406.00451\",\n",
    "#         \"2406.00447v1\",\n",
    "#         \"2406.00439v1\",\n",
    "#         \"2406.00430v1\",\n",
    "#         \"2406.00375v1\",\n",
    "#         \"2406.00364v1\",\n",
    "#         \"2406.00315v1\",\n",
    "#         \"2406.00313v2\",\n",
    "#         \"2406.00312v1\",\n",
    "#         # Add more paper DOIs or IDs as needed\n",
    "#     ]\n",
    "    \n",
    "#     # Batch the requests to avoid overloading\n",
    "#     batch_size = 10\n",
    "#     all_citation_counts = {}\n",
    "    \n",
    "#     for i in range(0, len(paper_ids), batch_size):\n",
    "#         batch = paper_ids[i:i + batch_size]\n",
    "#         citation_counts = get_citation_counts(batch, api_key)\n",
    "#         all_citation_counts.update(citation_counts)\n",
    "#         time.sleep(3)  # Add delay to avoid hitting rate limits\n",
    "\n",
    "#     for title, count in all_citation_counts.items():\n",
    "#         print(f\"Citation count for '{title}': {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://api.semanticscholar.org/graph/v1/paper/batch'\n",
    "# # headers = {'x-api-key': api_key}\n",
    "\n",
    "# # paper_ids = [paper.entry_id.split(\"/\")[-1] for paper in sorted_data]\n",
    "# paper_ids = [paper.entry_id for paper in sorted_data]\n",
    "\n",
    "# # Prepare the request payload\n",
    "# request_payload = {\n",
    "#     \"ids\": paper_ids,\n",
    "#     \"fields\": \"title,citationCount\"\n",
    "# }\n",
    "\n",
    "# # response = requests.post(url, headers=headers, json=request_payload)\n",
    "# response = requests.post(url, json=request_payload)\n",
    "# data = response.json()\n",
    "\n",
    "# citation_counts = {}\n",
    "# for paper in data['data']:\n",
    "#     title = paper.get('title', 'Unknown Title')\n",
    "#     citation_count = paper.get('citationCount', 0)\n",
    "#     citation_counts[title] = citation_count\n",
    "\n",
    "# citation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_semantic_scholar_batch(titles, api_key=None):\n",
    "    url = 'https://api.semanticscholar.org/graph/v1/paper/batch'\n",
    "    \n",
    "    # Prepare the request payload\n",
    "    request_payload = {\n",
    "        \"queries\": [{\"query\": title} for title in titles],\n",
    "        \"fields\": \"title,authors,doi,corpusId\"\n",
    "    }\n",
    "    \n",
    "    headers = {}\n",
    "    if api_key:\n",
    "        headers['x-api-key'] = api_key\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=request_payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [paper.title for paper in results]\n",
    "# search_semantic_scholar_batch(titles)\n",
    "url = 'https://api.semanticscholar.org/graph/v1/paper/batch'\n",
    "\n",
    "# Prepare the request payload\n",
    "request_payload = {\n",
    "    \"queries\": [{\"query\": title} for title in titles],\n",
    "    \"fields\": \"title,authors,doi,corpusId\"\n",
    "}\n",
    "\n",
    "# headers = {}\n",
    "# if api_key:\n",
    "#     headers['x-api-key'] = api_key\n",
    "\n",
    "# response = requests.post(url, headers=headers, json=request_payload)\n",
    "response = requests.post(url, json=request_payload)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Invalid input JSON'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Learning to Play Air Hockey with Model-Based Deep Reinforcement Learning'},\n",
       " {'query': 'Research on an Autonomous UAV Search and Rescue System Based on the Improved'},\n",
       " {'query': 'TacShade A New 3D-printed Soft Optical Tactile Sensor Based on Light, Shadow and Greyscale for Shape Reconstruction'},\n",
       " {'query': 'Task Planning for Object Rearrangement in Multi-room Environments'},\n",
       " {'query': 'DroneVis: Versatile Computer Vision Library for Drones'},\n",
       " {'query': 'Learning Manipulation by Predicting Interaction'},\n",
       " {'query': 'Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM Planners'},\n",
       " {'query': 'Teledrive: An Embodied AI based Telepresence System'},\n",
       " {'query': 'Cognitive Manipulation: Semi-supervised Visual Representation and Classroom-to-real Reinforcement Learning for Assembly in Semi-structured Environments'},\n",
       " {'query': 'Precision and Adaptability of YOLOv5 and YOLOv8 in Dynamic Robotic Environments'},\n",
       " {'query': 'From Seedling to Harvest: The GrowingSoy Dataset for Weed Detection in Soy Crops via Instance Segmentation'},\n",
       " {'query': 'NuRF: Nudging the Particle Filter in Radiance Fields for Robot Visual Localization'}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{\"query\": title} for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = requests.get(\"https://api.semanticscholar.org/graph/v1/paper/search?query=semantic%20scholar%20platform&limit=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 33619,\n",
       " 'offset': 0,\n",
       " 'next': 3,\n",
       " 'data': [{'paperId': 'cb92a7f9d9dbcf9145e32fdfa0e70e2a6b828eb1',\n",
       "   'title': 'The Semantic Scholar Open Data Platform'},\n",
       "  {'paperId': '0be97f920c0370c2a1f0784e49b7513d93f4436a',\n",
       "   'title': 'The JSTOR Academic Knowledge Graph: Structural Analysis and Primary Services and Applications with Reference to the Semantic Scholar Open Data Platform'},\n",
       "  {'paperId': '6648762d7755511993eec4177a3badfc37b77937',\n",
       "   'title': 'Implementation of Open Scholar Platform and Integration of Open Resources in National Taiwan Normal University (NTNU)'}]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2402333809.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[107], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    https://api.semanticscholar.org/graph/v1/paper/search?query=semantic%20scholar%20platform&limit=3\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "https://api.semanticscholar.org/graph/v1/paper/search?query=semantic%20scholar%20platform&limit=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv.Result"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Author',\n",
       " 'Link',\n",
       " 'MissingFieldError',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_from_feed_entry',\n",
       " '_get_default_filename',\n",
       " '_get_pdf_url',\n",
       " '_raw',\n",
       " '_to_datetime',\n",
       " 'authors',\n",
       " 'categories',\n",
       " 'comment',\n",
       " 'doi',\n",
       " 'download_pdf',\n",
       " 'download_source',\n",
       " 'entry_id',\n",
       " 'get_short_id',\n",
       " 'journal_ref',\n",
       " 'links',\n",
       " 'pdf_url',\n",
       " 'primary_category',\n",
       " 'published',\n",
       " 'summary',\n",
       " 'title',\n",
       " 'updated']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Author',\n",
       " 'Link',\n",
       " 'MissingFieldError',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_from_feed_entry',\n",
       " '_get_default_filename',\n",
       " '_get_pdf_url',\n",
       " '_raw',\n",
       " '_to_datetime',\n",
       " 'authors',\n",
       " 'categories',\n",
       " 'comment',\n",
       " 'doi',\n",
       " 'download_pdf',\n",
       " 'download_source',\n",
       " 'entry_id',\n",
       " 'get_short_id',\n",
       " 'journal_ref',\n",
       " 'links',\n",
       " 'pdf_url',\n",
       " 'primary_category',\n",
       " 'published',\n",
       " 'summary',\n",
       " 'title',\n",
       " 'updated']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__format__() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__format__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__format__() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "results[0].__format__(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
